<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <meta name="viewport"
          content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0, user-scalable=no, minimal-ui">
    <link rel="profile" href="http://gmpg.org/xfn/11">
    <link href="images/favicon.png" rel="shortcut icon">
    <link href="images/favicon.png" rel="apple-touch-icon-precomposed">

    <title>Home - Scraper API</title>
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100;200;300;400;500;600;700;800;900&display=swap"
          rel="stylesheet">
    <link rel="stylesheet" href="assets/css/style.css">
</head>

<body>

<header id="Hdr_main" class="header">
    <nav class="navbar navbar-expand-lg">
        <a class="navbar-brand" href="index.html">scraper<span>api</span></a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarText"
                aria-controls="navbarText" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"><i class="fa fa-bars" aria-hidden="true"></i></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarText">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item">
                    <a class="nav-link" href="pricing.html">Pricing</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="documentation.html">Documentation</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="affiliates.html">Affiliates</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://danni057272.typeform.com/to/P8e4If">Support</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" href="https://danni057272.typeform.com/to/sMpSSx">Contact Sales</a>
                </li>
            </ul>
            <div class="login-link-nav d-flex align-items-center">
                <a class="nav-link" href="http://dash.mawais.com/login">Login</a>
                <a href="http://dash.mawais.com/signup" class="btn btn-blue-nav">Sign Up</a>
            </div>
        </div>
    </nav>
</header>

<section class="main-section">
    <div class="banner-div home-banner">
        <div class="row">
            <div class="col-lg-6 col-md-12 col-xs-12 col-sm-12">
                <div class="banner-text">
                    <h1>Proxy API for <br>Web Scraping</h1>
                    <p>Scraper API handles proxies, browsers, and CAPTCHAs, so you can get the HTML from any web page
                        with a simple API call!</p>
                    <a href="http://dash.mawais.com/signup" class="btn btn-blue">Free Trial</a>
                    <p class="request-text-banner">Get started with <strong>5,000</strong> free requests. No credit card
                        required</p>
                </div>
            </div>
            <div class="col-lg-6 col-md-12 col-xs-12 col-sm-12">
                <div id="container" class="banner-code-img"></div>
            </div>
        </div>
        <div class="banner-logos">
            <p>Join the <strong>10,000+</strong> companies and developers using Scraper API</p>
            <ul>
                <li>
                    <img src="images/amzon-logo.png" alt=""/>
                </li>
                <li>
                    <img src="images/saymantec-logo.png" alt=""/>
                </li>
                <li>
                    <img src="images/legal-zoom-logo.png" alt=""/>
                </li>
                <li>
                    <img src="images/opendoor-logo.png" alt=""/>
                </li>
            </ul>
        </div>
    </div>
    <div class="main-inner-section">
        <div class="dots1 dots-img">
            <img src="images/home-dots2.svg" alt=""/>
        </div>
        <div class="dots2 dots-img">
            <img src="images/home-dots1.svg" alt=""/>
        </div>
        <div class="dots4 dots-img">
            <img src="images/home-dots4.svg" alt=""/>
        </div>
        <div class="container">
            <div class="row">
                <div class="how-it-works-section">
                    <div class="how-it-section-heading">
                        <h2>Using Proxies Has Never Been This Simple</h2>
                        <p>Simply send Scraper API the URL you want to scrape and we will return the HTML response.
                            Letting you focus on the data, not proxies.</p>
                    </div>
                    <img src="images/scheme-purple-img.svg" alt=""/>
                    <div class="how-it-btn">
                        <p>Easily scrape any site with JS rendering, geotargeting or residential proxies.</p>
                        <a href="#" class="scroll-down btn btn-blue" data-scrollto="howitworks">How it works?</a>
                    </div>
                    <div class="feature-div">
                        <ul>
                            <li>
                                <img src="images/small-icon1.svg" alt=""/>
                                <p>40M IPs Around the World</p>
                            </li>
                            <li>
                                <img src="images/small-icon2.svg" alt=""/>
                                <p>50+ Geolocations</p>
                            </li>
                            <li>
                                <img src="images/small-icon3.svg" alt=""/>
                                <p>99.9% Uptime Guarantee</p>
                            </li>
                            <li>
                                <img src="images/small-icon4.svg" alt=""/>
                                <p>Unlimited Bandwidth</p>
                            </li>
                            <li>
                                <img src="images/small-icon5.svg" alt=""/>
                                <p>24/7 Professional Support</p>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="feature-section-2">
        <div class="container">
            <div class="row">
                <div class="feature-inner">
                    <div class="row">
                        <div class="col-md-6 col-xs-12 col-sm-12">
                            <img src="images/Illustration-1-curl-v2.svg" alt=""/>
                        </div>
                        <div class="col-md-6 col-xs-12 col-sm-12 d-flex align-items-center">
                            <div class="feature-text">
                                <h2>Never Get Blocked</h2>
                                <p>With anti-bot detection and bypassing built into the API you never need to worry
                                    about having your requests blocked.</p>
                                <a href="http://dash.mawais.com/signup" class="btn btn-blue">Get A Free API Key</a>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="feature-inner">
                    <div class="row flex-md-row-reverse">
                        <div class="col-md-6 col-xs-12 col-sm-12">
                            <img src="images/faq-img02.svg" alt=""/>
                        </div>
                        <div class="col-md-6 col-xs-12 col-sm-12 d-flex align-items-center">
                            <div class="feature-text">
                                <h2>Fast and Reliable</h2>
                                <p>We automatically prune slow proxies from our pools, and guarantee unlimited bandwidth
                                    with speeds up to 100Mb/s, perfect for speedy web crawlers.</p>
                                <a href="http://dash.mawais.com/signup" class="btn btn-blue">Get A Free API Key</a>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="feature-inner">
                    <div class="row">
                        <div class="col-md-6 col-xs-12 col-sm-12">
                            <img src="images/faq-img03.svg" alt=""/>
                        </div>
                        <div class="col-md-6 col-xs-12 col-sm-12 d-flex align-items-center">
                            <div class="feature-text">
                                <h2>Built For Scale</h2>
                                <p>Whether you need to scrape 100 pages per month or 100 million pages per month,
                                    Scraper API can give you the scale you need.</p>
                                <a href="http://dash.mawais.com/signup" class="btn btn-blue">Get A Free API Key</a>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="customisable-div gray-bg">
        <div class="container">
            <div class="customisable-heaing" id="howitworks">
                <h2>Easy to Use and Fully Customisable</h2>
                <p>Built with developers in mind Scraper API is not only easy to integrate, it is even easier to
                    customize. Simply add <code>&render=true</code> , <code>&country_code=us</code> or <code>&premium=true</code>
                    to enable JS rendering, IP geolocation, residential proxies, and more.</p>
            </div>
            <div class="mode-section">
                <script type="text/javascript">
                    var curl = {
                    "api_makingPOSTRequest": "# Replace POST with PUT to send a PUT request instead\ncurl -d 'foo=bar' \\\n-X POST \\\n\"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/anything\"\n\n# For form data\ncurl -H 'Content-Type: application/x-www-form-urlencoded' \\\n-F 'foo=bar' \\\n-X POST \\\n\"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/anything\"",
                    "api_makingRequest": "curl \"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip",
                    "api_renderingJavascript": "curl \"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&render=true\"",
                    "api_customHeaders": "curl --header \"X-MyHeader: 123\" \\\"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/anything&keep_headers=true\"",
                    "api_sessions": "curl \"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&session_number=123\"",
                    "api_deviceType": "curl \"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&device_type=mobile\"",
                    "api_geographic": "curl \"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&country_code=us\"",
                    "api_premiumPools": "curl \"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&premium=true\"",
                    "api_autoParsing": "curl \"http://api.scraperapi.com/?api_key=YOURAPIKEY&url=https://www.amazon.com/dp/B07V1PHM66&autoparse=true\"",
                    "api_accountInformation": "curl \"http://api.scraperapi.com/account?api_key=YOURAPIKEY\"",
                    "proxy_makingPOSTRequest": "//Replace POST with PUT to send a PUT request instead\ncurl -d 'foo=bar' \\\n-X POST \\\n-x \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/anything\"\n\n//For form data\ncurl -H 'Content-Type: application/x-www-form-urlencoded' \\\n-F 'foo=bar' \\\n-X POST \\\n-x \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/anything\"",
                    "proxy_makingRequest": "curl \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/ip\"",
                    "proxy_renderingJavascript": "curl \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/ip\"",
                    "proxy_customHeaders": "curl --header \"X-MyHeader: 123\" \\-x \"http://scraperapi.keep_headers=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/anything\"",
                    "proxy_sessions": "curl \"http://scraperapi.session_number=123:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/ip\"",
                    "proxy_deviceType": "curl \"http://scraperapi.device_type=mobile:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/ip\"",
                    "proxy_geographic": "curl \"http://scraperapi.country_code=us:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/ip\"",
                    "proxy_autoParsing": "curl \"http://scraperapi.autoparse=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"https://www.amazon.com/dp/B07V1PHM66\"",
                    "proxy_premiumPools": "curl \"http://scraperapi.premium=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\" -k \"http://httpbin.org/ip\"",
                    "proxy_accountInformation": ""
                }
                var java = {
                    "api_makingRequest": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/ip\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_customHeaders": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/anything&keep_headers=true\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection httpURLConnection = (HttpURLConnection) urlForGetRequest.openConnection();\n  httpURLConnection.setRequestProperty(\"Content-Type\", \"application/json\");\n  httpURLConnection.setRequestProperty(\"X-MyHeader\", \"123\");\n  httpURLConnection.setRequestMethod(\"GET\");\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_renderingJavascript": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/ip&render=true\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_sessions": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/ip&session_number=123\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_deviceType": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/ip&device_type=mobile\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n }\n\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_geographic": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/ip&country_code=us\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_autoParsing": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/ip&autoparse=true\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_premiumPools": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com?api_key=\" + apiKey + \"&url=http://httpbin.org/ip&premium=true\";\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n     }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "api_accountInformation": "try {\n\n  String apiKey = \"YOURAPIKEY\";\n  String url = \"http://api.scraperapi.com/account?api_key=\" + apiKey;\n  URL urlForGetRequest = new URL(url);\n  String readLine = null;\n  HttpURLConnection conection = (HttpURLConnection) urlForGetRequest.openConnection();\n  conection.setRequestMethod(\"GET\");\n  int responseCode = conection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(conection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_makingRequest": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/ip\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_renderingJavascript": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi.render=true:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/ip\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_customHeaders": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi.keep_headers=true:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/anything\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.setRequestProperty(\"Content-Type\", \"application/json\");\n  httpURLConnection.setRequestProperty(\"X-MyHeader\", \"123\");\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_sessions": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi.session_number=123:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/ip\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_deviceType": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi.device_type=mobile:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/ip\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n     in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_geographic": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi.country_code=us:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/ip\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}\n",
                    "proxy_autoParsing": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi.autoparse=true:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/ip\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n      BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n      StringBuffer response = new StringBuffer();\n      while ((readLine = in.readLine()) != null) {\n          response.append(readLine);\n      }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n      throw new Exception(\"Error in API Call\");\n  }\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_premiumPools": "try {\n  String apiKey = \"YOURAPIKEY\";\n  String proxy = \"http://scraperapi.premium=true:\" + apiKey + \"@proxy-server.scraperapi.com\";\n  URL server = new URL(\"http://httpbin.org/ip\");\n  Properties systemProperties = System.getProperties();\n  systemProperties.setProperty(\"http.proxyHost\", proxy);\n  systemProperties.setProperty(\"http.proxyPort\", \"8001\");\n  HttpURLConnection httpURLConnection = (HttpURLConnection) server.openConnection();\n  httpURLConnection.connect();\n  String readLine = null;\n  int responseCode = httpURLConnection.getResponseCode();\n  if (responseCode == HttpURLConnection.HTTP_OK) {\n     BufferedReader in = new BufferedReader(new InputStreamReader(httpURLConnection.getInputStream()));\n     StringBuffer response = new StringBuffer();\n     while ((readLine = in.readLine()) != null) {\n         response.append(readLine);\n     }\n      in.close();\n      System.out.println(response.toString());\n  } else {\n  throw new Exception(\"Error in API Call\");\n }\n\n} catch (Exception ex) {\n  ex.printStackTrace();\n}",
                    "proxy_accountInformation": "",
                    "sdk_makingRequest": "// remember to install the library: https://search.maven.org/artifact/com.scraperapi/sdk/1.0\nimport com.scraperapi\nScraperApiClient client = new ScraperApiClient(\"e897c58f4d27e85b11ca43f09cb075ff\");\n  client.get(\"http://httpbin.org/ip\")\n  .result();",
                    "sdk_customHeaders": "// Coming soon.",
                    "sdk_renderingJavascript": "// remember to install the library: https://search.maven.org/artifact/com.scraperapi/sdk/1.0\nScraperApiClient client = new ScraperApiClient(\"YOURAPIKEY\");\n  client.get(\"http://httpbin.org/ip\")\n  .render(true)\n  .result();",
                    "sdk_sessions": "// Coming soon.",
                    "sdk_deviceType": "// Coming soon.",
                    "sdk_geographic": "// Coming soon.",
                    "sdk_autoParsing": "// remember to install the library: https://search.maven.org/artifact/com.scraperapi/sdk/1.0\nScraperApiClient client = new ScraperApiClient(\"YOURAPIKEY\");\n  client.get(\"http://httpbin.org/ip\")\n  .autoparse(true)\n  .result();",
                    "sdk_premiumPools": "// remember to install the library: https://search.maven.org/artifact/com.scraperapi/sdk/1.0\nScraperApiClient client = new ScraperApiClient(\"YOURAPIKEY\");\n  client.get(\"http://httpbin.org/ip\")\n  .premium(true)\n  .result();",
                    "sdk_accountInformation": "// Coming soon."
                }
                var node = {
                    "api_makingPOSTRequest": "const request = require('request-promise');\n\n// Replace POST with PUT to send a PUT request instead\noptions = {\n  method: 'POST',\n  url: 'http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/post',\n  body: JSON.stringify({foo: 'bar'}),\n  headers: {\n      'Content-Type': 'application/json',\n  },\n}\n\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })\n\n//For form data\noptions = {\n  method: 'POST',\n  url: http://api.scraperapi.com/?api_key=&#x24;{api_key}&url=http://httpbin.org/post,\n  form: {foo: 'bar'},\n  headers: {\n      'Content-Type': 'application/x-www-form-urlencoded',\n  },\n}\n\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "api_makingRequest": "const request = require('request-promise');\n  \n  request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip')\n    .then(response => {\n        console.log(response)\n    })\n    .catch(error => {\n        console.log(error)\n    })",
                    "api_customHeaders": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/anything&keep_headers=true',\n  headers: {\n      Accept: 'application/json',\n      'X-MyHeader': '123',\n  },\n}\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "api_renderingJavascript": "const request = require('request-promise');\n\nrequest('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&render=true')\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "api_sessions": "const request = require('request-promise');\n\nrequest('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&session_number=123')\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "api_deviceType": "const request = require('request-promise');\n\nrequest('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&device_type=mobile')\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "api_geographic": "const request = require('request-promise');\n\nrequest('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&country_code=us')\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "api_autoParsing": "const request = require('request-promise');\n\nrequest('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=https://www.amazon.com/dp/B07V1PHM66&autoparse=true')\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "api_premiumPools": "const request = require('request-promise');\n\nrequest('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=http://httpbin.org/ip&premium=true')\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "api_accountInformation": "const request = require('request-promise');\n\nrequest('http://api.scraperapi.com/account?api_key=YOURAPIKEY')\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "proxy_makingRequest": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://httpbin.org/ip',\n  proxy: 'http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001'\n}\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "proxy_makingPOSTRequest": "const request = require('request-promise');\n\noptions = {\n        method: 'POST',\n        url: 'http://httpbin.org/anything',\n        proxy:'http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001',\n        body: JSON.stringify({foo: 'bar'}),\n        headers: {\n            'Content-Type': 'application/json',\n        },\n    }\n\n request(options)\n    .then(response => {\n         console.log(response)\n     })\n      .catch(error => {\n         console.log(error)\n      })",
                    "proxy_renderingJavascript": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://httpbin.org/ip',\n  proxy: 'http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001'\n}\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "proxy_customHeaders": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://httpbin.org/anything',\n  proxy:'http://scraperapi.keep_headers=true:YOURAPIKEY@proxy-server.scraperapi.com:8001',\n  headers: {\n      Accept: 'application/json',\n      'X-MyHeader': '123',\n  },\n}\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "proxy_sessions": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://httpbin.org/ip',\n  proxy:'http://scraperapi.session_number=123:YOURAPIKEY@proxy-server.scraperapi.com:8001'\n}\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n})",
                    "proxy_deviceType": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://httpbin.org/ip',\n  proxy:'http://scraperapi.device_type=mobile:YOURAPIKEY@proxy-server.scraperapi.com:8001'\n}\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "proxy_geographic": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://httpbin.org/ip',\n  proxy:'http://scraperapi.country_code=us:YOURAPIKEY@proxy-server.scraperapi.com:8001'\n}\nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })\n",
                    "proxy_autoParsing": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'https://www.amazon.com/dp/B07V1PHM66',\n  proxy:'http://scraperapi.autoparse=true:YOURAPIKEY@proxy-server.scraperapi.com:8001'\n}\nrequest(options)\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "proxy_premiumPools": "const request = require('request-promise');\n\noptions = {\n  method: 'GET',\n  url: 'http://httpbin.org/ip',\n  proxy:'http://scraperapi.premium=true:YOURAPIKEY@proxy-server.scraperapi.com:8001'\n}\n    \nrequest(options)\n  .then(response => {\n      console.log(response)\n  })\n  .catch(error => {\n      console.log(error)\n  })",
                    "proxy_accountInformation": "",
                    "sdk_makingRequest": "const scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\n\n// scraperapiClient.get('http://httpbin.org/ip')\n// .then(response => {\n//     console.log(response)\n// })\n// .catch(error => {\n//     console.log(error)\n// })",
                    "sdk_makingPOSTRequest": "const scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\n\noptions = {\n  body: JSON.stringify({foo: 'bar'}),\n  headers: {\n      'Content-Type': 'application/json',\n  }\n}\n\n//POST\nscraperapiClient.post('http://httpbin.org/anything', options)\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})\n\n//PUT\nscraperapiClient.put('http://httpbin.org/anything', options)\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_renderingJavascript": "// remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\n\nscraperapiClient.get('http://httpbin.org/ip', {render: true})\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_customHeaders": "// remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\nscraperapiClient.get('http://httpbin.org/anything', {headers: {'X-MyHeader': '123'}})\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_sessions": "// remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\nscraperapiClient.get('http://httpbin.org/ip', {session_number: 123})\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_deviceType": "// remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\n\nscraperapiClient.get('http://httpbin.org/ip', {device_type: 'mobile'})\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_geographic": "// // remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\nscraperapiClient.get('http://httpbin.org/ip', {country_code: 'us'})\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_autoParsing": "// remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\nscraperapiClient.get('https://www.amazon.com/dp/B07V1PHM66', {autoparse: true})\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_premiumPools": "// remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\n\nscraperapiClient.get('http://httpbin.org/ip', {premium: true})\n.then(response => {\n  console.log(response)\n})\n.catch(error => {\n  console.log(error)\n})",
                    "sdk_accountInformation": "// remember to install the library: npm install scraperapi-sdk --save\nconst scraperapiClient = require('scraperapi-sdk')('YOURAPIKEY')\n\nscraperapiClient.account()\n.then(response => console.log(response))"
                }
                var php = {
                    "api_makingRequest": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_makingPOSTRequest": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/anything\";\n\n# POST/PUT Requests\n$postData = [\"foo\" => \"bar\"];\n$postData = json_encode($postData);\n$headers = [\n  \"Content-Type: application/json\"\n];\n\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_POST, 1);\ncurl_setopt($ch, CURLOPT_POSTFIELDS, $postData);  //Post Fields\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n\n$response = curl_exec($ch);\ncurl_close($ch);\n\nprint_r($response);\n\n\n#Form POST Request\n$postData = [\"foo\" => \"bar\"];\n$postData = json_encode($postData);\n$headers = [\n  'Content-Type: application/x-www-form-urlencoded; charset=utf-8',\n];\n\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_POST, true);\ncurl_setopt($ch, CURLOPT_POSTFIELDS, $postData);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n\n$response = curl_exec($ch);\ncurl_close($ch);\n\nprint_r($response);",
                    "api_customHeaders": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip&keep_headers=true\";\n$headerArray = array(\n  \"Content-Type: application/json\",\n  \"X-MyHeader: 123\"\n);\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headerArray);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_renderingJavascript": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip&render=true\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_sessions": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip&session_number=123\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_deviceType": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip&device_type=mobile\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_geographic": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip&country_code=us\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_autoParsing": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip&autoparse=true\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_premiumPools": "&lt;?php\n$url = \"http://api.scraperapi.com?api_key=YOURAPIKEY&url=http://httpbin.org/ip&premium=true\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "api_accountInformation": "&lt;?php\n$url = \"http://api.scraperapi.com/account?api_key=YOURAPIKEY\";\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, $url);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nprint_r($response);",
                    "proxy_makingRequest": "&lt;?php\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);",
                    "proxy_makingPOSTRequest": "&lt;?php\n\n$postData = [\"foo\"=>\"bar\"];\n$postData = json_encode($postData);\n$headers = [\n  \"Content-Type: application/json\"\n];\n\n//POST/PUT Request\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_POST, 1);\ncurl_setopt($ch, CURLOPT_POSTFIELDS, $postData);  //Post Fields\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n\n$response = curl_exec($ch);\ncurl_close($ch);\n\nvar_dump($response);\nputs results \n\n//Form Data POST Request\n$postData = [\"foo\"=>\"bar\"];\n$postData = json_encode($postData);\n$headers = [\n  'Content-Type: application/x-www-form-urlencoded; charset=utf-8',\n];\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_POST, true);\ncurl_setopt($ch, CURLOPT_POSTFIELDS, $postData);\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, true);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headers);\n$response = curl_exec($ch);\ncurl_close($ch);\n\nprint_r($response);",
                    "proxy_renderingJavascript": "&lt;?php\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);",
                    "proxy_customHeaders": "&lt;?php\n$headerArray = array(\n  \"Content-Type: application/json\",\n  \"X-MyHeader: 123\"\n);\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi.keep_headers=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HTTPHEADER, $headerArray);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);",
                    "proxy_sessions": "&lt;?php\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi.session_number=123:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);",
                    "proxy_deviceType": "&lt;?php\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi.device_type=mobile:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);",
                    "proxy_geographic": "&lt;?php\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi.country_code=us:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);\n",
                    "proxy_autoParsing": "&lt;?php\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi.autoparse=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);",
                    "proxy_premiumPools": "&lt;?php\n$ch = curl_init();\ncurl_setopt($ch, CURLOPT_URL, \"http://httpbin.org/ip\");\ncurl_setopt($ch, CURLOPT_PROXY, \"http://scraperapi.premium=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\");\ncurl_setopt($ch, CURLOPT_RETURNTRANSFER, TRUE);\ncurl_setopt($ch, CURLOPT_HEADER, FALSE);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYHOST, 0);\ncurl_setopt($ch, CURLOPT_SSL_VERIFYPEER, 0);\n$response = curl_exec($ch);\ncurl_close($ch);\nvar_dump($response);",
                    "proxy_accountInformation": "",
                    "sdk_makingRequest": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n  $client = new ScraperAPIClient(\"YOURAPIKEY\");\n  $postResult = $client->post(\"http://httpbin.org/ip\", [\"foo\" => \"bar\"])->raw_body;\n  $putResult = $client->put(\"http://httpbin.org/ip\", [\"foo\" => \"bar\"])->raw_body;\n\n  print($putResult);",
                    "sdk_makingPOSTRequest": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n  $client = new ScraperAPIClient(\"YOURAPIKEY\");\n  $postResult = $client->post(\"http://httpbin.org/ip\", [\"foo\" => \"bar\"])->raw_body;\n  $putResult = $client->put(\"http://httpbin.org/ip\", [\"foo\" => \"bar\"])->raw_body;\n\n  print($putResult);",
                    "sdk_customHeaders": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n  $client = new ScraperAPIClient(\"YOURAPIKEY\");\n  $result = $client->get(\"http://httpbin.org/ip\", [\"headers\" => [\"X-MyHeader\" => \"123\"]])->raw_body;\n  print($result);",
                    "sdk_sessions": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n  $client = new ScraperAPIClient(\"YOURAPIKEY\");\n  $result = $client->get(\"http://httpbin.org/ip\", [\"session_number\" => 123])->raw_body;\n  print($result);",
                    "sdk_deviceType": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n$client = new ScraperAPIClient(\"YOURAPIKEY\");\n$result = $client->get(\"http://httpbin.org/ip\", [\"device_type\" => \"mobile\"])->raw_body;\nprint($result);",
                    "sdk_geographic": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n  $client = new ScraperAPIClient(\"YOURAPIKEY\");\n  $result = $client->get(\"http://httpbin.org/ip\", [\"country_code\" => \"US\"])->raw_body;\n  print($result);",
                    "sdk_autoParsing": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n$client = new ScraperAPIClient(\"YOURAPIKEY\");\n$result = $client->get(\"http://httpbin.org/ip\", [\"autoparse\" => true])->raw_body;\nprint($result);",
                    "sdk_premiumPools": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n$client = new ScraperAPIClient(\"YOURAPIKEY\");\n$result = $client->get(\"http://httpbin.org/ip\", [\"premium\" => true])->raw_body;\nprint($result);",
                    "sdk_renderingJavascript": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n$client = new ScraperAPIClient(\"YOURAPIKEY\");\n$result = $client->get(\"http://httpbin.org/ip\", [\"render\" => true])->raw_body;\nprint($result);",
                    "sdk_accountInformation": "# remember to install the library: composer require scraperapi/sdk\n&lt;?php\n$client = new ScraperAPIClient(\"YOURAPIKEY\");\n$usage = $client.account();\nprint($usage);"
                }
                var python = {
                    "api_makingRequest": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url': 'https://httpbin.org/ip'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# ...other scrapy setup code\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url]\n\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url, self.parse)\n",
                    "api_makingPOSTRequest": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url': 'https://httpbin.org/anything'}\n\nr = requests.post('http://api.scraperapi.com', params=payload, data={'foo': 'bar'})\nprint(r.text)",
                    "api_customHeaders": "import requests\nurl = 'http://httpbin.org/anything'\nheaders = {\n  'Accept': 'application/json'\n  'X-MyHeader': '123',\n}\npayload = {'api_key': 'YOURAPIKEY', 'url': 'https://httpbin.org/ip', 'keep_headers': 'true'}\nr = requests.get('http://api.scraperapi.com', params=payload, headers=headers)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function in their parse function\n# ...other scrapy setup code\nheaders = {\n  'Accept': 'application/json'\n  'X-MyHeader': '123',\n}\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url + '&keep_headers=true']\n\ndef parse(self, response):\n  # ...your parsing logic here\n  scraper_url = 'http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url + '&keep_headers=true'\n  yield scrapy.Request(scraper_url, self.parse, headers=headers)",
                    "api_renderingJavascript": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url':'https://httpbin.org/ip', 'render': 'true'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# ...other scrapy setup code\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url + '&render=true']\n\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url + '&render=true', self.parse)",
                    "api_sessions": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url':'https://httpbin.org/ip', 'session_number': '123'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# ...other scrapy setup code\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url + '&session_number=123']\n\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url + '&session_number=123', self.parse)",
                    "api_deviceType": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url':'https://httpbin.org/ip', 'device_type': 'mobile'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# ...other scrapy setup code\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url + 'device_type=mobile']\n\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url + 'device_type=mobile', self.parse)",
                    "api_geographic": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url':'https://httpbin.org/ip', 'country_code': 'us'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# ...other scrapy setup code\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url + 'country_code=us']\n\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url + 'country_code=us', self.parse)",
                    "api_autoParsing": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url':'https://www.amazon.com/dp/B07V1PHM66', 'autoparse': 'true'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# ...other scrapy setup code\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url + 'autoparse=true']\n\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url + 'autoparse=true', self.parse)",
                    "api_premiumPools": "import requests\npayload = {'api_key': 'YOURAPIKEY', 'url':'https://httpbin.org/ip', 'premium': 'true'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# ...other scrapy setup code\nstart_urls = ['http://api.scraperapi.com?api_key=YOURAPIKEY&url=' + url + 'premium=true']\n\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request('http://api.scraperapi.com/?api_key=YOURAPIKEY&url=' + url + 'premium=true', self.parse)",
                    "api_accountInformation": "import requests\npayload = {'api_key': 'YOURAPIKEY'}\nr = requests.get('http://api.scraperapi.com', params=payload)\nprint r.text",
                    "proxy_makingRequest": "import requests\nproxies = {\n  \"http\": \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('http://httpbin.org/ip', proxies=proxies, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['http://httpbin.org/ip']\nmeta = {\n  \"proxy\": \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)",
                    "proxy_makingPOSTRequest": "import requests\nproxies = {\n  \"http\": \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\n\nr = requests.post('http://httpbin.org/anything', proxies=proxies, data={'foo': 'bar'}, verify=False)\nprint(r.text)",
                    "proxy_renderingJavascript": "import requests\nproxies = {\n  \"http\": \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('http://httpbin.org/ip', proxies=proxies, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['http://httpbin.org/ip']\nmeta = {\n  \"proxy\": \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)",
                    "proxy_customHeaders": "import requests\nheaders = {\n  'Accept': 'application/json'\n  'X-MyHeader': '123',\n}\nproxies = {\n  \"http\": \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('http://httpbin.org/ip', proxies=proxies, headers=headers, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['http://httpbin.org/ip']\nmeta = {\n  \"proxy\": \"http://scraperapi.render=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nheaders = {\n  'Accept': 'application/json'\n  'X-MyHeader': '123',\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)\n",
                    "proxy_sessions": "import requests\nproxies = {\n  \"http\": \"http://scraperapi.session_number=123:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi.session_number=123:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('http://httpbin.org/ip', proxies=proxies, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['http://httpbin.org/ip']\nmeta = {\n  \"proxy\": \"http://scraperapi.session_number=123:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)",
                    "proxy_deviceType": "import requests\nproxies = {\n  \"http\": \"http://scraperapi.device_type=mobile:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi.device_type=mobile:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('http://httpbin.org/ip', proxies=proxies, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['http://httpbin.org/ip']\nmeta = {\n  \"proxy\": \"http://scraperapi.device_type=mobile:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)",
                    "proxy_geographic": "import requests\nproxies = {\n  \"http\": \"http://scraperapi.country_code=us:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi.country_code=us:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('http://httpbin.org/ip', proxies=proxies, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['http://httpbin.org/ip']\nmeta = {\n  \"proxy\": \"http://scraperapi.country_code=us:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)\n",
                    "proxy_autoParsing": "import requests\nproxies = {\n  \"http\": \"http://scraperapi.autoparse=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi.autoparse=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('https://www.amazon.com/dp/B07V1PHM66', proxies=proxies, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['https://www.amazon.com/dp/B07V1PHM66']\nmeta = {\n  \"proxy\": \"http://scraperapi.autoparse=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)",
                    "proxy_premiumPools": "import requests\nproxies = {\n  \"http\": \"http://scraperapi.premium=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\",\n  \"https\": \"http://scraperapi.premium=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\nr = requests.get('http://httpbin.org/ip', proxies=proxies, verify=False)\nprint(r.text)\n\n# Scrapy users can likewise simply pass their API key in headers.\n# NB: Scrapy skips SSL verification by default.\n# ...other scrapy setup code\nstart_urls = ['http://httpbin.org/ip']\nmeta = {\n  \"proxy\": \"http://scraperapi.premium=true:YOURAPIKEY@proxy-server.scraperapi.com:8001\"\n}\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(url, callback=self.parse, headers=headers, meta=meta)",
                    "proxy_accountInformation": "",
                    "sdk_makingRequest": "# remember to install the library: pip install scraperapi-sdk\nfrom scraper_api import ScraperAPIClient\nclient = ScraperAPIClient(YOURAPIKEY)\nresult = client.get(url = 'http://httpbin.org/ip').text\nprint(result)\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'http://httpbin.org/ip')]\ndef parse(self, response):\n  # ...your parsing logic here\n  yield scrapy.Request(client.scrapyGet(url = 'http://httpbin.org/ip'), self.parse)",
                    "sdk_makingPOSTRequest": "# remember to install the library: pip install scraperapi-sdk\n  from scraper_api import ScraperAPIClient\n  client = ScraperAPIClient('YOURAPIKEY')\n  \n  postResult = client.post(url = 'http://httpbin.org/anything', body = {'foo': 'bar'}}).text\n  putResult = client.put(url = 'http://httpbin.org/anything', body = {'foo': 'bar'}}).text\n  \n  print(postResult)\n  print(putResult)",
                    "sdk_customHeaders": "// # remember to install the library: pip install scraperapi-sdk\nfrom scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nresult = client.get(url = 'http://httpbin.org/ip', \"headers\" = {\"X-MyHeader\": \"123\"}).text\nprint(result)\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'http://httpbin.org/ip', headers={\"X-MyHeader\": \"123\"})]\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(client.scrapyGet(url = 'http://httpbin.org/ip', \"headers\"={\"X-MyHeader\": \"123\"}), self.parse)",
                    "sdk_renderingJavascript": "from scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nresult = client.get(url = 'http://httpbin.org/ip', render=true).text\nprint(result)\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'http://httpbin.org/ip', render=true)]\ndef parse(self, response):\n\n# ...your parsing logic here\nyield scrapy.Request(client.scrapyGet(url = 'http://httpbin.org/ip', render=true), self.parse)",
                    "sdk_sessions": "// from scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nresult = client.get(url = 'http://httpbin.org/ip', session_number=123).text\nprint(result)\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'http://httpbin.org/ip', session_number=123)]\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(client.scrapyGet(url = 'http://httpbin.org/ip', session_number=123), self.parse)",
                    "sdk_deviceType": "# remember to install the library: pip install scraperapi-sdk\nfrom scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nresult = client.get(url = 'http://httpbin.org/anything', device_type = 'mobile').text\nprint(result)\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'http://httpbin.org/anything', device_type = 'mobile')]\ndef parse(self, response):\n\n# ...your parsing logic here\nyield scrapy.Request(client.scrapyGet(url = 'http://httpbin.org/anything', device_type = 'mobile'), self.parse)",
                    "sdk_geographic": "// from scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nresult = client.get(url = 'http://httpbin.org/ip', country_code=us).text\nprint(result)\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'http://httpbin.org/ip', country_code=us)]\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(client.scrapyGet(url = 'http://httpbin.org/ip', country_code=us), self.parse)",
                    "sdk_autoParsing": "// from scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nresult = client.get(url = 'https://www.amazon.com/dp/B07V1PHM66', autoparse=true).text\nprint(result)\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'https://www.amazon.com/dp/B07V1PHM66', autoparse=true)]\ndef parse(self, response):\n# ...your parsing logic here\nyield scrapy.Request(client.scrapyGet(url = 'https://www.amazon.com/dp/B07V1PHM66', autoparse=true), self.parse)",
                    "sdk_premiumPools": "from scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nresult = client.get(url = 'http://httpbin.org/ip', premium=true).text\nprint(result)\n\n# Scrapy users can simply replace the urls in their start_urls and parse function\n# Note for Scrapy, you should not use DOWNLOAD_DELAY and\n# RANDOMIZE_DOWNLOAD_DELAY, these will lower your concurrency and are not\n# needed with our API\n\n# ...other scrapy setup code\nstart_urls =[client.scrapyGet(url = 'http://httpbin.org/ip', premium=true)]\ndef parse(self, response):\n\n# ...your parsing logic here\nyield scrapy.Request(client.scrapyGet(url = 'http://httpbin.org/ip', premium=true), self.parse)",
                    "sdk_accountInformation": "# remember to install the library: pip install scraperapi-sdk\nfrom scraper_api import ScraperAPIClient\nclient = ScraperAPIClient('YOURAPIKEY')\nusage = client.account()\nprint(usage)"
                }
                var ruby = {
                    "api_makingRequest": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/ip\"\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "api_makingPOSTRequest": "require 'net/http'\nrequire 'json'\n\n## Replace POST with PUT to send a PUT request instead\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/anything\"\n}\n\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\n\nwebsite_content = Net::HTTP.post(uri, { \"foo\" => \"bar\"}.to_json, \"Content-Type\" => \"application/json\")    \nprint(website_content.body)\n\n## For form data\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/anything\"\n}\n\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\n\nreq = Net::HTTP::Post.new(uri)\nreq.set_form_data('foo' => 'bar')\n\nwebsite_content = Net::HTTP.start(uri.hostname, uri.port) {|http|\n  http.request(req)\n}\n\nprint(website_content.body)",
                    "api_renderingJavascript": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/ip\",\n  :render => true\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "api_customHeaders": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/anything\",\n  :keep_headers => true\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nreq = Net::HTTP::Get.new(uri)\nreq['Accept'] = 'application/json'\nreq['X-MyHeader'] = '123'\nwebsite_content = Net::HTTP.start(uri.hostname, uri.port) {|http|\n  http.request(req)\n}\nprint(website_content.body)",
                    "api_sessions": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/ip\",\n  :session_number => 123\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "api_deviceType": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/ip\",\n  :device_type => “mobile”\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "api_geographic": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/ip\",\n  :country_code => “us”\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "api_autoParsing": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/ip\",\n  :autoparse => true\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "api_premiumPools": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\",\n  :url => \"http://httpbin.org/ip\",\n  :premium => true\n}\nuri = URI('http://api.scraperapi.com/')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "api_accountInformation": "require 'net/http'\nrequire 'json'\nparams = {\n  :api_key => \"YOURAPIKEY\"\n}\nuri = URI('http://api.scraperapi.com/account')\nuri.query = URI.encode_www_form(params)\nwebsite_content = Net::HTTP.get(uri)\nprint(website_content)",
                    "proxy_makingRequest": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nresponse = HTTParty.get('http://httpbin.org/ip', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi\",\n  http_proxypass: \"YOURAPIKEY\"\n})\nresults = response.body\nputs results",
                    "proxy_makingPOSTRequest": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nquery = {'foo': 'bar'}\n\n## POST/PUT Request\nheaders = {'Accept':'application/json', 'Content-Type':'application/json'}\n\nresponse = HTTParty.post('http://httpbin.org/anything', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi\",\n  http_proxypass: \"YOURAPIKEY\",\n  body: query.to_json,\n  headers: headers\n}, )\nresults = response.body\nputs results \n\n## Form POST Request\nheaders = {'Accept':'application/json'}\n\nresponse = HTTParty.post('http://httpbin.org/anything', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi\",\n  http_proxypass: \"YOURAPIKEY\",\n  body: query.to_json,\n  headers: headers\n}, )\nresults = response.body\nputs results ",
                    "proxy_renderingJavascript": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nresponse = HTTParty.get('http://httpbin.org/ip', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi.render=true\",\n  http_proxypass: \"YOURAPIKEY\"\n})\nresults = response.body\nputs results",
                    "proxy_customHeaders": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nheaders = {'Accept': 'application/json', 'X-MyHeader': '123'}\nresponse = HTTParty.get('http://httpbin.org/anything', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi.keep_headers=true\",\n  http_proxypass: \"YOURAPIKEY\",\n  headers: headers\n}, )\nresults = response.body\nputs results ",
                    "proxy_sessions": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nresponse = HTTParty.get('http://httpbin.org/ip', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi.session_number=123\",\n  http_proxypass: \"YOURAPIKEY\"\n})\nresults = response.body\nputs results ",
                    "proxy_deviceType": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nresponse = HTTParty.get('http://httpbin.org/ip', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi.device_type=mobile\",\n  http_proxypass: \"YOURAPIKEY\"\n})\nresults = response.body\nputs results",
                    "proxy_geographic": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nresponse = HTTParty.get('http://httpbin.org/ip', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi.country_code=us\",\n  http_proxypass: \"YOURAPIKEY\"\n})\nresults = response.body\nputs results\n",
                    "proxy_autoParsing": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nresponse = HTTParty.get('http://httpbin.org/ip', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi.autoparse=true\",\n  http_proxypass: \"YOURAPIKEY\"\n})\nresults = response.body\nputs results ",
                    "proxy_premiumPools": "require 'httparty'\nHTTParty::Basement.default_options.update(verify: false)\nresponse = HTTParty.get('http://httpbin.org/ip', {\n  http_proxyaddr: \"proxy-server.scraperapi.com\",\n  http_proxyport: \"8001\",\n  http_proxyuser: \"scraperapi.premium=true\",\n  http_proxypass: \"YOURAPIKEY\"\n})\nresults = response.body\nputs results ",
                    "proxy_accountInformation": "",
                    "sdk_renderingJavascript": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\", render: true).raw_body\nputs result",
                    "sdk_makingRequest": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\").raw_body\nputs result",
                    "sdk_makingPOSTRequest": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\n\n#POST/PUT Requests\npostResult = client.post(\"http://httpbin.org/ip\", \"foo\": \"bar\").raw_body\nputResult = client.put(\"http://httpbin.org/ip\", \"foo\": \"bar\").raw_body\n\nputs postResult\nputs putResult\n\n#Form Post Requests\nformResult = client.post(\"http://httpbin.org/anything\", body: {\"foo\": \"bar\"}, headers: {\"Accept\":\"application/json\"}).raw_body\nputs formResult",
                    "sdk_customHeaders": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\", headers: {\"X-MyHeader\" => \"123\"}).raw_body\nputs result",
                    "sdk_sessions": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\", session_number: 123).raw_body\nputs result",
                    "sdk_deviceType": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\", device_type: “mobile”).raw_body\nputs result",
                    "sdk_geographic": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\", country_code: \"US\").raw_body\nputs result",
                    "sdk_autoParsing": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\", autoparse: true).raw_body\nputs result",
                    "sdk_premiumPools": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nresult = client.get(\"http://httpbin.org/ip\", premium: true).raw_body\nputs result",
                    "sdk_accountInformation": "# remember to install the library: gem install scraperapi\nrequire \"scraper_api\"\nclient = ScraperAPI::Client.new(\"YOURAPIKEY\")\nputs client.account()"
                }
                </script>
                <nav>
                    <div class="nav nav-tabs change-mode" id="nav-tab" role="tablist">
                        <a class="nav-item nav-link active" id="api-mode-tab" data-mode="api" data-toggle="tab"
                           href="#api-mode" role="tab" aria-controls="api-mode" aria-selected="true">API Mode</a>
                        <a class="nav-item nav-link" id="proxy-mode-tab" data-mode="proxy" data-toggle="tab"
                           href="#proxy-mode" role="tab" aria-controls="proxy-mode" aria-selected="false">Proxy Mode</a>
                    </div>
                </nav>
                <div class="tab-content" id="nav-tabContent">
                    <div class="tab-pane fade show active" id="api-mode" role="tabpanel" aria-labelledby="api-mode-tab">
                        <div class="api-mode-section">
                            <ul class="tags-btns change-language">
                                <li class="active">
                                    <button type="button" class="btn-tag" data-language="bash">Bash</button>
                                </li>
                                <li>
                                    <button type="button" class="btn-tag" data-language="javascript">Node</button>
                                </li>
                                <li>
                                    <button type="button" class="btn-tag" data-language="python">Python/Scrapy</button>
                                </li>
                                <li>
                                    <button type="button" class="btn-tag" data-language="php">PHP</button>
                                </li>
                                <li>
                                    <button type="button" class="btn-tag" data-language="ruby">Ruby</button>
                                </li>
                                <li>
                                    <button type="button" class="btn-tag" data-language="java">Java</button>
                                </li>
                            </ul>
                            <div class="row">
                                <div class="col-md-8">
                                    <div class="code-section">
                                        <div class="code-toolbar">
                                            <div class="application-topbar">
                                                <div class="application-actions-container">
                                                    <div class="application-action application-action-close"></div>
                                                    <div class="application-action application-action-minimize"></div>
                                                    <div class="application-action application-action-maximize"></div>
                                                </div>
                                                <div class="application-title-container" data-title-container="">bash
                                                </div>
                                            </div>
                                            <div class="application-content-container">
                                                <pre>
                                                <code class="language-python" id="code_box">curl &quot;http://api.scraperapi.com/?api_key=APIKEY&amp;url=http://httpbin.org/ip</code>
                                                </pre>
                                            </div>
                                        </div>
                                        <div class="code-dots dots-img">
                                            <img src="images/api-bg-dots.svg" alt=""/>
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-4">
                                    <div class="api-list">
                                        <ul class="home-section-menu">
                                            <li class="active">
                                                <a href="#" data-code="makingRequest">GET Requests</a>
                                            </li>
                                            <li>
                                                <a href="#" data-code="renderingJavascript">Javascript Rendering</a>
                                            </li>
                                            <li>
                                                <a href="#" data-code="geographic">IP Geotargetting</a>
                                            </li>
                                            <li>
                                                <a href="#" data-code="premiumPools">Residential Proxies</a>
                                            </li>
                                            <li>
                                                <a href="#" data-code="customHeaders">Custom Headers</a>
                                            </li>
                                            <li>
                                                <a href="#" data-code="sessions">Custom Sessions</a>
                                            </li>
                                            <li>
                                                <a href="#" data-code="autoParsing">JSON Autoparsing</a>
                                            </li>
                                        </ul>
                                        <a class="show-all-link" href="/documentation">Show All API Documentation</a>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="tab-pane fade" id="proxy-mode" role="tabpanel" aria-labelledby="proxy-mode-tab">...
                    </div>
                </div>
                <div class="plateform-logo">
                    <p>Extensive documentation & SDKs available for:</p>
                    <ul>
                        <li>
                            <img src="images/python-logo.png" alt=""/>
                        </li>
                        <li>
                            <img src="images/node-logo.png" alt=""/>
                        </li>
                        <li>
                            <img src="images/php-logo.png" alt=""/>
                        </li>
                        <li>
                            <img src="images/ruby-logo.png" alt=""/>
                        </li>
                        <li>
                            <img src="images/java-logo.png" alt=""/>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
    <div class="customisable-div">
        <div class="container">
            <div class="customer-review-section">
                <div class="customer-review-heading">
                    <h2>What our customers are saying</h2>
                    <p>One of the most frustrating parts of automated web scraping is constantly dealing with IP blocks
                        and CAPTCHAs. Scraper API rotates IP addresses with each request.</p>
                </div>
                <div class="customer-card-section">
                    <div class="row">
                        <div class="col-lg-4 col-md-6">
                            <div class="customer-card">
                                <img class="comment-icon" src="/images/comment-icon.svg" alt=""/>
                                <div class="customer-card-img">
                                    <img src="images/bitmap1.png" alt=""/>
                                </div>
                                <div class="customer-card-heading">
                                    <h3>Cristina Saavedra</h3>
                                    <p>Optimization Director at SquareTrade</p>
                                </div>
                                <div class="customer-card-text">
                                    <p>The team at Scraper API was so patient in helping us debug our first scraper.
                                        Thanks for being super passionate and awesome!</p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-4 col-md-6">
                            <div class="customer-card">
                                <img class="comment-icon" src="/images/comment-icon.svg" alt=""/>
                                <div class="customer-card-img">
                                    <img src="images/bitmap2.png" alt=""/>
                                </div>
                                <div class="customer-card-heading">
                                    <h3>Ilya Sukhar</h3>
                                    <p>Founder of Parse, Partner at YCombinator</p>
                                </div>
                                <div class="customer-card-text">
                                    <p>A dead simple API plus a generous free tier are hard to beat. Scraper API is a
                                        good example of how developer experience can make a difference in a crowded
                                        category.</p>
                                </div>
                            </div>
                        </div>
                        <div class="col-lg-4 col-md-6">
                            <div class="customer-card">
                                <img class="comment-icon" src="/images/comment-icon.svg" alt=""/>
                                <div class="customer-card-img">
                                    <img src="images/bitmap3.png" alt=""/>
                                </div>
                                <div class="customer-card-heading">
                                    <h3>Matt Lee</h3>
                                    <p>Freelance Software Engineer</p>
                                </div>
                                <div class="customer-card-text">
                                    <p>The team at Scraper API was so patient in helping us debug our first scraper.
                                        Thanks for being super passionate and awesome!</p>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="customer-logo">
                        <ul>
                            <li>
                                <img src="images/customer-logo01.png" alt=""/>
                            </li>
                            <li>
                                <img src="images/customer-logo02.png" alt=""/>
                            </li>
                            <li>
                                <img src="images/customer-logo03.png" alt=""/>
                            </li>
                            <li>
                                <img src="images/customer-logo04.png" alt=""/>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <div class="signup-section signup-section-home">
        <div class="container">
            <div class="ready-scraping-heading">
                <h2>Ready to start scraping?</h2>
                <p>Get started with 5,000 free API calls or <a href="https://danni057272.typeform.com/to/sMpSSx">contact
                    sales</a></p>
            </div>
            <div class="signup-inner">
                <button class="google btn social-btn w-100" type="button">
                    <img src="images/google-icon.svg" class="social-login-ico" alt="Login With Google"/>Sign Up with
                    Google
                </button>
                <button class="github btn social-btn w-100" type="button">
                    <img src="images/github-icon.svg" class="social-login-ico" alt="Login With Github"/>Sign Up with
                    Github
                </button>
                <p>Or Sign Up with Email</p>
                <input class="form-control" id="email" type="email" name="" placeholder="Email"/>
                <input class="form-control" id="password" type="password" name="" placeholder="Password"/>
                <input class="btn btn-blue w-100" id="email-signup" type="button" value="Sign Up"/>
                <div id="error-message" class="text-center text-danger mt-2"></div>
            </div>
        </div>
    </div>
</section>

<footer>
    <div class="footer-main">
        <div class="row">
            <div class="col-lg-3 col-md-6">
                <div class="footer-text">
                    <h3>Our Story</h3>
                    <p>Having built many web scrapers, we repeatedly went through the tiresome process of finding
                        proxies, setting up headless browsers, and handling CAPTCHAs. That's why we decided to start
                        Scraper API, it handles all of this for you so you can scrape any page with a simple API
                        call!</p>
                </div>
            </div>
            <div class="col-lg-3 col-md-6">
                <div class="footer-links">
                    <h3>Product</h3>
                    <ul>
                        <li>
                            <a href="affiliates.html">Affiliates</a>
                        </li>
                        <li>
                            <a href="pricing.html">Pricing</a>
                        </li>
                        <li>
                            <a href="documentation.html">Documentation</a>
                        </li>
                        <li>
                            <a href="http://dash.mawais.com/signup">Sign Up</a>
                        </li>
                        <li>
                            <a href="/blog">Blog</a>
                        </li>
                    </ul>
                </div>
            </div>
            <div class="col-lg-3 col-md-6">
                <div class="footer-links">
                    <h3>Resources</h3>
                    <ul>
                        <li>
                            <a href="https://www.scraperapi.com/blog/the-10-best-datacenter-https-and-static-proxy-providers-for-web-scraping/">Datacenter
                                and Static Proxies</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/best-10-free-proxies-and-free-proxy-lists-for-web-scraping/">Free
                                Proxies for Web Scraping</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/10-best-mobile-3g-4g-proxy-providers-for-web-scraping/">Mobile,
                                3G and 4G Proxies</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/best-dedicated-shared-virgin-proxy-providers-for-web-scraping/">Dedicated
                                and Shared Proxies</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/best-ipv6-proxy-providers-for-web-scraping/">IPv6
                                Proxies</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/the-10-best-rotating-proxy-services-for-web-scraping">Residential
                                Rotating Proxies</a>
                        </li>
                    </ul>
                </div>
            </div>
            <div class="col-lg-3 col-md-6">
                <div class="footer-links">
                    <h3>&nbsp;</h3>
                    <ul>
                        <li>
                            <a href="https://www.scraperapi.com/blog/the-10-best-web-scraping-tools">Web Scraping
                                Tools</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/5-tips-for-web-scraping">Web Scraping Tips</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/free-shared-dedicated-datacenter-residential-rotating-proxies-for-web-scraping">Web
                                Scraping Proxies</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/5-tips-for-build-large-scale-web-scrapers">Large
                                Scale Scraping Tips</a>
                        </li>
                        <li>
                            <a href="https://www.scraperapi.com/blog/web-scraper-proxies-in-house-or-outsource">Inhouse
                                or Outsource</a>
                        </li>
                        <li>
                            <a href="privacy.html">Privacy policy</a>
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </div>
    <div class="footer-bottom-bar">
        <div class="row">
            <div class="col-md-6">
                <div class="footer-logo">
                    <a href="index.html">scraper<span>api</span></a>
                </div>
            </div>
            <div class="col-md-6 text-right">
                <p>©scraperapi</p>
            </div>
        </div>
    </div>
</footer>

<script src="assets/js/main.js"></script>
</body>

</html>